# located in: core/prompting/promptspecs/simula.react.step.yaml

# Unique identifier for this specific prompt configuration.
id: simula_step_v3
version: "3.0.0"

# The scope used by the orchestrator to invoke this prompt. [cite: 518]
scope: simula.react.step

# Defines the agent's identity and core instructions.
identity:
  agent: Simula
  persona_partial: simula_persona # Jinja template for the system message [cite: 475, 495]

# Defines safety guardrails and constitutional rules.
safety:
  partials:
    - safety_guardrails # Jinja template for safety instructions [cite: 475, 495]

# Specifies which context lenses to run to enrich the prompt data. [cite: 472, 495]
context_lenses:
  - equor.identity # Fetches the agent's summary and purpose. [cite: 430]

# Defines the main body of the prompt using template partials. [cite: 476, 495]
partials:
  - simula_react_main # The primary user-facing prompt template.

# Defines how the LLM's output should be handled. [cite: 492]
outputs:
  parse_mode: auto_repair # Gracefully handles malformed JSON from the LLM. [cite: 477, 484]
  schema_ref: "schemas/react_action.json" # Points to a JSON schema for validation.

# Sets the token budget for the LLM call. [cite: 494]
budget_policy:
  max_tokens_fallback: 4096