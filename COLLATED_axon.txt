# ===== EcodiaOS Collation =====
# Generated: 2025-08-31T12:57:54
# Root: D:\EcodiaOS\systems
# Systems: axon
# Extensions: .py
# Ignored dirs: .git, .hg, .idea, .svn, .venv, .vscode, __pycache__, node_modules, venv

# ===== DIRECTORY: D:\EcodiaOS\systems\axon =====

# ===== FILE: D:\EcodiaOS\systems\axon\__init__.py =====

# ===== FILE: D:\EcodiaOS\systems\axon\dependencies.py =====
# systems/axon/dependencies.py
from __future__ import annotations

from functools import cache

from systems.axon.mesh.registry import DriverRegistry
from systems.axon.mesh.scorecard import ScorecardManager
from systems.axon.mesh.lifecycle import DriverLifecycleManager
from systems.axon.safety.conformal import ConformalPredictor
from systems.axon.safety.circuit_breaker import CircuitBreaker
from systems.axon.safety.contracts import ContractsEngine
from systems.axon.journal.mej import MerkleJournal
from systems.axon.io.quarantine import Quarantine


@cache
def get_driver_registry() -> DriverRegistry:
    return DriverRegistry()

@cache
def get_scorecard_manager() -> ScorecardManager:
    return ScorecardManager(window_max=500)

@cache
def get_lifecycle_manager() -> DriverLifecycleManager:
    # Use canonical artifact dir so synthesis/promotions are consistent
    return DriverLifecycleManager(artifact_dir="systems/axon/drivers/generated")

@cache
def get_conformal_predictor() -> ConformalPredictor:
    return ConformalPredictor(max_residuals=512, q=0.9)

@cache
def get_circuit_breaker() -> CircuitBreaker:
    return CircuitBreaker(window_sec=60, min_success=0.85, burst_fail_cap=5, cooldown_sec=30)

@cache
def get_contracts_engine() -> ContractsEngine:
    return ContractsEngine().with_default_rules()

@cache
def get_journal() -> MerkleJournal:
    return MerkleJournal()

@cache
def get_quarantine() -> Quarantine:
    return Quarantine()

# ===== FILE: D:\EcodiaOS\systems\axon\schemas.py =====
# systems/axon/schemas.py

from typing import Literal

from pydantic import BaseModel, Field


class AxonEvent(BaseModel):
    """
    The fundamental unit of sensory information flowing from Axon to Atune.
    Represents a single, atomic observation of the external world.
    """

    event_id: str = Field(..., description="Unique identifier for the event.")
    t_observed: float = Field(..., description="UNIX timestamp of observation.")
    source: str = Field(..., description="The origin of the event, e.g., a specific driver.")
    event_type: str = Field(..., description="Categorical type of the event.")
    modality: Literal[
        "text",
        "html",
        "json",
        "audio",
        "video",
        "image",
        "tabular",
        "graph",
        "binary",
    ]
    payload_ref: str | None = Field(
        None,
        description="Reference to the raw payload, if stored separately.",
    )
    parsed: dict | None = Field(None, description="The structured, parsed content of the event.")
    embeddings: dict[str, list[float]] = Field(
        default_factory=dict,
        description="Embeddings for various aspects of the event.",
    )
    provenance: dict = Field(..., description="Traceable origin: driver_id, version, checksums.")
    salience_hints: dict = Field(
        default_factory=dict,
        description="Initial fast-computed hints for Atune's FAE.",
    )
    quality: dict = Field(default_factory=dict, description="Metrics on the data quality.")
    triangulation: dict = Field(
        default_factory=dict,
        description="Cross-corroboration and contradiction flags.",
    )
    cost_ms: int | None = Field(None, description="Milliseconds taken to generate this event.")
    cost_usd: float | None = Field(None, description="Estimated USD cost to generate this event.")


class AxonIntent(BaseModel):
    """
    A validated, resourced, and authorized intention to act in the world.
    This is sent from Atune/Synapse to Axon for execution.
    """

    intent_id: str = Field(..., description="Unique identifier for the intent.")
    purpose: str = Field(..., description="Plain-language reason for the action, for auditability.")
    target_capability: str = Field(
        ...,
        description="The specific capability this intent invokes, e.g., 'twitter:post_tweet'.",
    )
    params: dict = Field(..., description="The parameters for the capability.")
    risk_tier: Literal["low", "mid", "high", "extreme"]
    constraints: dict = Field(
        ...,
        description="Operational constraints, e.g., max_retries, timeout_ms.",
    )
    policy_trace: dict = Field(
        ...,
        description="Chain of decisions: synapse_plan_hash, unity_verdict, equor_cap_token.",
    )
    rollback_contract: dict = Field(
        ...,
        description="A description of how to undo or neutralize this action.",
    )


class ActionResult(BaseModel):
    """
    The measured result of executing an AxonIntent. This closes the loop.
    """

    intent_id: str = Field(..., description="The ID of the intent that was executed.")
    status: Literal["ok", "fail", "blocked"]
    outputs: dict = Field(..., description="The direct outputs from the driver execution.")
    side_effects: dict = Field(..., description="Observed, indirect consequences of the action.")
    counterfactual_metrics: dict = Field(
        ...,
        description="Metrics comparing the outcome to the Simula twin's prediction.",
    )
    follow_up_events: list[str] = Field(
        default_factory=list,
        description="IDs of new AxonEvents generated by this action.",
    )

# ===== FILE: D:\EcodiaOS\systems\axon\ab\runner.py =====
# systems/axon/ab/runner.py
from __future__ import annotations

import copy
import time
from typing import Any

from systems.axon.dependencies import get_driver_registry, get_scorecard_manager
from systems.axon.learning.feedback import ingest_action_outcome
from systems.axon.safety.twin import run_in_twin
from systems.axon.schemas import ActionResult, AxonIntent

def _mk_shadow_intent(intent: AxonIntent, shadow_name: str) -> AxonIntent:
    shadow = copy.deepcopy(intent)
    shadow.intent_id = f"{intent.intent_id}::ab::{shadow_name[:8]}"
    constraints = dict(shadow.constraints or {})
    constraints["dry_run"] = True
    shadow.constraints = constraints
    if isinstance(shadow.policy_trace, dict):
        shadow.policy_trace["ab_parent"] = intent.intent_id
    return shadow

async def run_ab_trial(intent: AxonIntent, *, decision_id: str | None = None) -> dict[str, Any]:
    reg = get_driver_registry()
    cards = get_scorecard_manager()
    cap = intent.target_capability
    out: dict[str, Any] = {"capability": cap, "intent_id": intent.intent_id, "twin": None, "shadows": []}

    # Twin prediction (baseline)
    t0 = time.perf_counter()
    twin_res: ActionResult = await run_in_twin(intent)
    twin_ms = (time.perf_counter() - t0) * 1000.0
    out["twin"] = {
        "status": twin_res.status,
        "latency_ms": twin_ms,
        "counterfactual_metrics": twin_res.counterfactual_metrics,
        "outputs": twin_res.outputs,
    }

    # Shadows (dry-run)
    shadows = reg.get_shadow_drivers_for_capability(cap) or []
    for sh in shadows:
        name = sh.describe().driver_name
        sh_intent = _mk_shadow_intent(intent, name)
        t1 = time.perf_counter()
        try:
            res: ActionResult = await sh.push(sh_intent)
            lat = (time.perf_counter() - t1) * 1000.0
            out["shadows"].append({
                "driver": name,
                "status": res.status,
                "latency_ms": lat,
                "counterfactual_metrics": res.counterfactual_metrics,
                "outputs": res.outputs,
            })
            # score uplift vs twin; send to Synapse ingest_outcome
            upl = res.counterfactual_metrics.get("actual_utility", 0.0) - twin_res.counterfactual_metrics.get("predicted_utility", 0.0)
            cards.update_scorecard(name, was_successful=(res.status == "ok"), latency_ms=lat, uplift=upl)
            await ingest_action_outcome(intent=sh_intent, predicted_result=twin_res, actual_result=res, decision_id=decision_id)

        except Exception as e:
            lat = (time.perf_counter() - t1) * 1000.0
            out["shadows"].append({"driver": name, "status": "fail", "latency_ms": lat, "error": str(e)})
            cards.update_scorecard(name, was_successful=False, latency_ms=lat, uplift=0.0)
            try:
                fail_res = ActionResult(
                    intent_id=sh_intent.intent_id,
                    status="fail",
                    outputs={"error": "shadow_exception", "details": str(e)},
                    side_effects={},
                    counterfactual_metrics={"actual_utility": 0.0},
                )
                await ingest_action_outcome(intent=sh_intent, predicted_result=twin_res, actual_result=fail_res, decision_id=decision_id)
            except Exception:
                pass

    return out

# ===== FILE: D:\EcodiaOS\systems\axon\core\act.py =====
# systems/axon/core/act.py
from __future__ import annotations

import time
from typing import Any

from systems.axon.dependencies import (
    get_driver_registry,
    get_scorecard_manager,
    get_conformal_predictor,
    get_circuit_breaker,
    get_contracts_engine,
    get_journal,
)
from systems.axon.events.builder import build_followups
from systems.axon.events.emitter import emit_followups_bg
from systems.axon.learning.feedback import ingest_action_outcome
from systems.axon.safety.twin import run_in_twin
from systems.axon.schemas import ActionResult, AxonIntent


async def execute_intent(intent: AxonIntent, *, decision_id: str | None = None) -> ActionResult:
    """
    Full Axon act pipeline: pre → twin → conformal → circuit → push → post → followups/journal → feedback
    """
    registry = get_driver_registry()
    scorecards = get_scorecard_manager()
    conformal = get_conformal_predictor()
    breaker = get_circuit_breaker()
    contracts = get_contracts_engine()
    journal = get_journal()

    # -------- preconditions --------
    pre = contracts.check_pre(intent)
    if not pre.ok:
        res = ActionResult(
            intent_id=intent.intent_id,
            status="blocked",
            outputs={"error": "preconditions_failed", "reason": pre.reason, "patches": pre.patches},
            side_effects={},
            counterfactual_metrics={},
        )
        try: journal.write_entry(res)
        except Exception: pass
        return res

    # -------- twin prediction --------
    twin = await run_in_twin(intent)
    predicted = float(twin.counterfactual_metrics.get("predicted_utility", 0.0))

    # -------- conformal bound --------
    bound = conformal.bound(predicted)

    # -------- circuit breaker --------
    cap = intent.target_capability
    if not breaker.allow(cap):
        res = ActionResult(
            intent_id=intent.intent_id,
            status="blocked",
            outputs={"error": "circuit_open"},
            side_effects={},
            counterfactual_metrics={"predicted_utility": predicted, "conformal": bound.__dict__},
        )
        try: journal.write_entry(res)
        except Exception: pass
        return res

    # -------- driver push (live) --------
    live = registry.get_live_driver_for_capability(cap)
    if live is None:
        res = ActionResult(
            intent_id=intent.intent_id,
            status="fail",
            outputs={"error": "no_live_driver", "capability": cap},
            side_effects={},
            counterfactual_metrics={"predicted_utility": predicted, "conformal": bound.__dict__},
        )
        try: journal.write_entry(res)
        except Exception: pass
        return res

    t0 = time.perf_counter()
    try:
        result = await live.push(intent)
        latency_ms = (time.perf_counter() - t0) * 1000.0
        breaker.report(cap, ok=(result.status == "ok"))
        actual_util = float(result.counterfactual_metrics.get("actual_utility", predicted))
        conformal.observe(predicted=predicted, actual=actual_util)

        # -------- postconditions --------
        post = contracts.check_post(intent, result)
        if not post.ok:
            # (Optional) rollback example
            rollback_status = "skipped"
            if getattr(intent, "rollback_contract", None):
                try:
                    rb = AxonIntent(
                        **{
                            **intent.model_dump(),
                            "intent_id": f"{intent.intent_id}::rollback",
                            "params": intent.rollback_contract.get("params", {}),
                        }
                    )
                    rb_res = await live.push(rb)
                    rollback_status = f"rollback_{rb_res.status}"
                except Exception as e:
                    rollback_status = f"rollback_fail:{e}"

            result = ActionResult(
                intent_id=intent.intent_id,
                status="fail",
                outputs={"error": "postconditions_failed", "reason": post.reason, "rollback": rollback_status},
                side_effects=result.side_effects,
                counterfactual_metrics=result.counterfactual_metrics,
                follow_up_events=result.follow_up_events,
            )

        # -------- follow-ups + journal --------
        try:
            for ev in build_followups(intent, result):
                emit_followups_bg([ev], decision_id=decision_id)
        except Exception:
            pass
        try:
            journal.write_entry(result)
        except Exception:
            pass

        # -------- scorecards --------
        upl = float(result.counterfactual_metrics.get("actual_utility", predicted) - predicted)
        scorecards.update_scorecard(
            live.describe().driver_name,
            was_successful=(result.status == "ok"),
            latency_ms=latency_ms,
            uplift=upl,
        )

        # -------- learning feedback (predicted vs actual) --------
        try:
            await ingest_action_outcome(intent=intent, predicted_result=twin, actual_result=result, decision_id=decision_id)
        except Exception:
            pass

        return result

    except Exception as e:
        breaker.report(cap, ok=False)
        res = ActionResult(
            intent_id=intent.intent_id,
            status="fail",
            outputs={"error": "driver_exception", "details": str(e)},
            side_effects={},
            counterfactual_metrics={"predicted_utility": predicted, "conformal": bound.__dict__},
        )
        try: journal.write_entry(res)
        except Exception: pass
        # still emit a feedback record for learning
        try:
            await ingest_action_outcome(intent=intent, predicted_result=twin, actual_result=res, decision_id=decision_id)
        except Exception:
            pass
        return res

# ===== FILE: D:\EcodiaOS\systems\axon\drivers\qora_search_driver.py =====
# systems/axon/drivers/qora_search_driver.py
from __future__ import annotations

import hashlib
import os
import time
import uuid
from typing import Any

from pydantic import BaseModel

from core.utils.net_api import ENDPOINTS, get_http_client
from systems.axon.mesh.sdk import CapabilitySpec, DriverInterface, HealthStatus, ReplayCapsule
from systems.axon.schemas import ActionResult, AxonIntent


class QoraSearchDriver(DriverInterface):
    NAME = "qora_search"
    VERSION = "1.0.0"
    CAPABILITY = "qora:search"

    def describe(self) -> CapabilitySpec:
        return CapabilitySpec(
            driver_name=self.NAME,
            driver_version=self.VERSION,
            supported_actions=[self.CAPABILITY],
            risk_profile={self.CAPABILITY: "normal"},
            budget_model={self.CAPABILITY: 1.0},
            auth_requirements=["api_key"],
        )

    async def self_test(self) -> HealthStatus:
        http = await get_http_client()
        try:
            r = await http.get(ENDPOINTS.QORA_ARCH_HEALTH)
            ok = (r.status_code // 100) == 2
            return HealthStatus(status="ok" if ok else "degraded", details=f"status={r.status_code}", dependencies={"qora": "ok" if ok else "error"})
        except Exception as e:
            return HealthStatus(status="error", details=str(e), dependencies={"qora": "error"})

    async def push(self, intent: AxonIntent) -> ActionResult:
        """
        Executes a search-then-execute against Qora. Respects constraints.dry_run.
        """
        http = await get_http_client()
        params = intent.params or {}
        body = {
            "query": params.get("query", ""),
            "safety_max": params.get("safety_max", 2),
            "top_k": params.get("top_k", 3),
            "system": params.get("system"),
        }
        # dry-run just returns a shaped stub
        if getattr(intent.constraints or {}, "dry_run", False):
            return ActionResult(status="dry_run", outputs={"preview": body}, side_effects=[], counterfactual_metrics={})

        r = await http.post(ENDPOINTS.QORA_ARCH_EXECUTE_BY_QUERY, json=body)
        r.raise_for_status()
        data = r.json()
        return ActionResult(status="ok", outputs=data, side_effects=[], counterfactual_metrics={})

    async def repro_bundle(self, *, id: str, kind: str) -> ReplayCapsule:
        """
        Build a deterministic capsule for the given item id (intent/event).
        We hash the relevant runtime environment + alias map to pin dependencies.
        """
        env_fingerprint = "|".join(
            [
                os.getenv("ECODIAOS_BASE_URL", ""),
                getattr(ENDPOINTS, "QORA_ARCH_EXECUTE_BY_QUERY", "/qora/arch/execute-by-query"),
                getattr(ENDPOINTS, "QORA_ARCH_HEALTH", "/qora/arch/health"),
                os.getenv("QORA_API_KEY", "dev")[:6],  # prefix only, avoids leaking full secret
            ]
        )
        env_hash = hashlib.blake2b(env_fingerprint.encode("utf-8"), digest_size=16).hexdigest()

        # In a full build we'd look up the original inputs/outputs from MEJ by id.
        # For now, package a minimal replay contract that can be executed directly.
        inputs = {"id": id, "kind": kind, "capability": self.CAPABILITY, "replay_howto": "POST ENDPOINTS.QORA_ARCH_EXECUTE_BY_QUERY with {query, safety_max, top_k, system}"}
        outputs: dict[str, Any] = {}

        return ReplayCapsule(
            id=str(uuid.uuid4()),
            type=kind,  # "intent" | "event"
            driver_version=self.VERSION,
            environment_hash=env_hash,
            inputs=inputs,
            outputs=outputs,
        )

# ===== FILE: D:\EcodiaOS\systems\axon\drivers\rss_driver.py =====
# systems/axon/drivers/rss_driver.py
from __future__ import annotations

import hashlib
import uuid
import xml.etree.ElementTree as ET
from collections.abc import AsyncIterator
from typing import Any

from core.utils.net_api import get_http_client
from systems.axon.mesh.sdk import CapabilitySpec, DriverInterface, HealthStatus, ReplayCapsule
from systems.axon.schemas import ActionResult, AxonEvent, AxonIntent


class RssDriver(DriverInterface):
    """Pull-only driver that ingests RSS feeds with replay support."""

    NAME = "rss"
    VERSION = "1.0.3"
    CAPABILITY = None  # no push

    def __init__(self):
        # pull_id → raw xml; guid → pull_id
        self._pull_cache: dict[str, str] = {}
        self._id_map: dict[str, str] = {}

    def describe(self) -> CapabilitySpec:
        return CapabilitySpec(
            driver_name=self.NAME,
            driver_version=self.VERSION,
            supported_actions=[],  # pull-only
            risk_profile={},
            budget_model={"pull": 1.0},
            auth_requirements=["none"],
        )

    async def pull(self, params: dict[str, Any]) -> AsyncIterator[AxonEvent]:
        """
        Pulls from a feed URL and yields AxonEvent(s) directly.
        """
        feed_url = params.get("url")
        if not feed_url:
            raise ValueError("RSS Driver 'pull' requires a 'url' in params.")

        client = await get_http_client()
        try:
            response = await client.get(feed_url)
            response.raise_for_status()
            raw_content = response.text

            pull_id = hashlib.sha256(raw_content.encode("utf-8")).hexdigest()
            self._pull_cache[pull_id] = raw_content

            root = ET.fromstring(raw_content)
            for item in root.findall(".//item"):
                title = (item.findtext("title") or "").strip()
                desc = (item.findtext("description") or "").strip()
                link = (item.findtext("link") or "").strip()
                guid = (item.findtext("guid") or link or str(uuid.uuid4())).strip()
                self._id_map[guid] = pull_id

                yield AxonEvent(
                    event_id=str(uuid.uuid4()),
                    t_observed=None,  # set by Atune on ingest if desired
                    source=f"rss:{feed_url}",
                    event_type="article_published",
                    modality="html",
                    payload_ref=link,
                    parsed={"title": title, "description": desc, "guid": guid},
                    embeddings={},
                    provenance={
                        "driver_id": self.NAME,
                        "version": self.VERSION,
                        "feed_url": feed_url,
                        "pull_id": pull_id,
                    },
                    salience_hints={},
                    quality={},
                    triangulation={},
                    cost_ms=None,
                    cost_usd=0.0,
                )
        except Exception as e:
            print(f"RssDriver failed for {feed_url}: {e}")
            return

    async def push(self, intent: AxonIntent) -> ActionResult:
        raise NotImplementedError("RssDriver does not support 'push'.")

    async def self_test(self) -> HealthStatus:
        # Basic health = we can instantiate and parse a tiny sample doc
        try:
            ET.fromstring("<rss><channel><item><title>x</title></item></channel></rss>")
            return HealthStatus(status="ok", details="XML parser OK")
        except Exception as e:
            return HealthStatus(status="error", details=f"xml error: {e}")

    async def repro_bundle(self, *, id: str, kind: str) -> ReplayCapsule:
        pull_id = self._id_map.get(id)  # here `id` is the item guid
        if not pull_id or pull_id not in self._pull_cache:
            raise KeyError(f"No cached content for GUID {id}")
        raw_content = self._pull_cache[pull_id]
        env_hash = hashlib.blake2b(pull_id.encode("utf-8"), digest_size=16).hexdigest()
        return ReplayCapsule(
            id=id,
            type="event",
            driver_version=self.VERSION,
            environment_hash=env_hash,
            inputs={"params": {"url": "unknown"}, "pull_id": pull_id},
            outputs={"raw_content": raw_content},
        )

# ===== FILE: D:\EcodiaOS\systems\axon\events\__init__.py =====
# systems/axon/events/__init__.py
from .builder import build_followups
from .emitter import emit_followups, emit_followups_bg

__all__ = ["build_followups", "emit_followups", "emit_followups_bg"]

# ===== FILE: D:\EcodiaOS\systems\axon\events\builder.py =====
# systems/axon/events/builder.py
from __future__ import annotations

from typing import Any

from systems.axon.schemas import ActionResult, AxonIntent


def _base_event(intent: AxonIntent, result: ActionResult, event_type: str, details: dict[str, Any]) -> dict[str, Any]:
    return {
        "event": {
            "source": "axon",
            "topic": f"axon::{event_type}",
            "payload": details,
            "intent": {
                "id": intent.intent_id,
                "capability": intent.target_capability,
                "risk_tier": getattr(intent, "risk_tier", None),
            },
            "result_meta": {
                "status": result.status,
                "driver_name": (getattr(result, "outputs", {}) or {}).get("driver_name"),
            },
            "raw": None,
        }
    }

def build_followups(intent: AxonIntent, result: ActionResult) -> list[dict[str, Any]]:
    out: list[dict[str, Any]] = []
    outputs = getattr(result, "outputs", {}) or {}
    status = getattr(result, "status", "unknown")

    # Always: compact result summary
    out.append(
        _base_event(
            intent,
            result,
            "action.result",
            {
                "status": status,
                "summary": outputs.get("summary") or outputs.get("message") or "",
                "metrics": getattr(result, "counterfactual_metrics", {}) or {},
            },
        ),
    )

    # Search → search.results
    search_hits = outputs.get("hits") or outputs.get("results")
    if isinstance(search_hits, list) and search_hits:
        top: list[dict[str, Any]] = []
        for h in search_hits[:10]:
            if not isinstance(h, dict):
                continue
            top.append(
                {
                    "title": str(h.get("title", ""))[:200],
                    "url": str(h.get("url", ""))[:400],
                    "snippet": str(h.get("snippet", ""))[:400],
                    "score": float(h.get("score", 0.0)) if h.get("score") is not None else None,
                },
            )
        if top:
            out.append(
                _base_event(
                    intent,
                    result,
                    "search.results",
                    {
                        "query": (getattr(intent, "params", {}) or {}).get("query", ""),
                        "results": top,
                    },
                ),
            )

    return out

# ===== FILE: D:\EcodiaOS\systems\axon\events\emitter.py =====
# systems/axon/events/emitter.py
from __future__ import annotations

import asyncio
import os
from typing import Any

from core.utils.net_api import ENDPOINTS, get_http_client

ENDPOINT_ATTRS = ("ATUNE_ROUTE", "ATUNE_COGNITIVE_CYCLE")
_DEBUG = os.getenv("AXON_DEBUG", "0") == "1"


async def emit_followups(events: list[dict[str, Any]], decision_id: str | None = None) -> None:
    if not events:
        return
    client = await get_http_client()

    # choose best-known endpoint name dynamically
    target = None
    for name in ENDPOINT_ATTRS:
        if hasattr(ENDPOINTS, name):
            target = getattr(ENDPOINTS, name)
            break
    target = target or "/atune/route"

    headers = {"x-budget-ms": os.getenv("AXON_EMIT_BUDGET_MS", "800")}
    if decision_id:
        headers["x-decision-id"] = decision_id

    try:
        if len(events) == 1 and hasattr(ENDPOINTS, "ATUNE_ROUTE"):
            resp = await client.post(getattr(ENDPOINTS, "ATUNE_ROUTE"), json=events[0], headers=headers)
            if _DEBUG:
                print(f"[Emitter] POST {getattr(ENDPOINTS, 'ATUNE_ROUTE')} → {resp.status_code}")
        else:
            if hasattr(ENDPOINTS, "ATUNE_COGNITIVE_CYCLE"):
                resp = await client.post(getattr(ENDPOINTS, "ATUNE_COGNITIVE_CYCLE"), json={ "events": events }, headers=headers)
                if _DEBUG:
                    print(f"[Emitter] POST {getattr(ENDPOINTS, 'ATUNE_COGNITIVE_CYCLE')} → {resp.status_code}")
            else:
                for ev in events:
                    resp = await client.post(target, json=ev, headers=headers)
                    if _DEBUG:
                        print(f"[Emitter] POST {target} → {resp.status_code}")
    except Exception as e:
        if _DEBUG:
            print(f"[Emitter] swallow error: {e}")
        return


def emit_followups_bg(events: list[dict[str, Any]], decision_id: str | None = None) -> None:
    try:
        asyncio.create_task(emit_followups(events, decision_id=decision_id))
    except Exception:
        pass

# ===== FILE: D:\EcodiaOS\systems\axon\io\quarantine.py =====
# systems/axon/io/quarantine.py

from html.parser import HTMLParser
from typing import Any, Literal

from pydantic import BaseModel, Field

# -----------------------------------------------------------------------------
# Data Contracts for Quarantine Output
# -----------------------------------------------------------------------------


class Taint(BaseModel):
    """A structured label indicating the source and nature of untrusted data."""

    origin_type: str = Field(
        ...,
        description="The source of the taint, e.g., 'html_script_tag', 'unverified_api'.",
    )
    level: Literal["low", "medium", "high"] = Field(
        "medium",
        description="The severity of the taint.",
    )


class CanonicalizedPayload(BaseModel):
    """The structured, sanitized output of the quarantine process."""

    content_type: Literal["text", "structured_data"]
    text_blocks: list[str] = Field(
        default_factory=list,
        description="Ordered, clean text extracted from the payload.",
    )
    structured_data: dict[str, Any] | None = Field(
        None,
        description="Clean, structured data if the source was a format like JSON.",
    )
    taints: list[Taint] = Field(
        ...,
        description="A list of all taints applied during canonicalization.",
    )


# -----------------------------------------------------------------------------
# Whitelist-based HTML Sanitizer
# -----------------------------------------------------------------------------


class HTMLSanitizer(HTMLParser):
    """
    A strict, whitelist-based HTML parser that extracts clean text
    and flags potentially malicious content by applying taints.
    """

    def __init__(self, allowed_tags: set[str]):
        super().__init__()
        self.allowed_tags = allowed_tags
        self.text_blocks: list[str] = []
        self.taints: list[Taint] = []
        self._tag_stack: list[str] = []

    def handle_starttag(self, tag: str, attrs: Any):
        if tag in self.allowed_tags:
            self._tag_stack.append(tag)
        else:
            self._tag_stack.append("BLOCKED")
            self.taints.append(Taint(origin_type=f"html_disallowed_tag_{tag}", level="medium"))

    def handle_endtag(self, tag: str):
        if self._tag_stack:
            self._tag_stack.pop()

    def handle_data(self, data: str):
        # Only accept data if we are inside an allowed tag
        if data.strip() and self._tag_stack and self._tag_stack[-1] != "BLOCKED":
            self.text_blocks.append(data.strip())

    @classmethod
    def sanitize(cls, html_content: str, allowed_tags: set[str]) -> tuple[list[str], list[Taint]]:
        parser = cls(allowed_tags=allowed_tags)
        parser.feed(html_content)
        return parser.text_blocks, parser.taints


# -----------------------------------------------------------------------------
# Main Quarantine Class
# -----------------------------------------------------------------------------


class Quarantine:
    """
    Handles the initial processing of raw, untrusted data from drivers.
    Its purpose is to sanitize, canonicalize, and apply taint before
    the data is allowed to become a formal AxonEvent.
    """

    def __init__(
        self,
        html_allowed_tags: set[str] = {
            "p",
            "b",
            "i",
            "strong",
            "em",
            "h1",
            "h2",
            "h3",
            "li",
            "ul",
            "ol",
        },
    ):
        self.html_allowed_tags = html_allowed_tags

    def process_and_canonicalize(self, raw_payload: Any, mime_type: str) -> CanonicalizedPayload:
        """
        Processes a raw payload according to its MIME type, returning a
        structured, sanitized, and tainted representation.
        """
        if "html" in mime_type:
            return self._canonicalize_html(raw_payload)
        elif "json" in mime_type:
            return self._canonicalize_json(raw_payload)
        else:  # Default to plain text handling
            return self._canonicalize_text(raw_payload)

    def _canonicalize_html(self, payload: Any) -> CanonicalizedPayload:
        if not isinstance(payload, str):
            return CanonicalizedPayload(
                content_type="text",
                text_blocks=[f"Error: HTML payload was not a string, but {type(payload)}"],
                taints=[Taint(origin_type="invalid_html_payload_type", level="high")],
            )

        text_blocks, taints = HTMLSanitizer.sanitize(payload, self.html_allowed_tags)
        taints.append(Taint(origin_type="source_html", level="low"))

        return CanonicalizedPayload(content_type="text", text_blocks=text_blocks, taints=taints)

    def _canonicalize_json(self, payload: Any) -> CanonicalizedPayload:
        taints = [Taint(origin_type="source_json", level="low")]
        if not isinstance(payload, dict):
            return CanonicalizedPayload(
                content_type="structured_data",
                structured_data={"error": f"JSON payload was not a dict, but {type(payload)}"},
                taints=[Taint(origin_type="invalid_json_payload_type", level="high")],
            )

        return CanonicalizedPayload(
            content_type="structured_data",
            structured_data=payload,  # Assuming JSON is already clean data
            taints=taints,
        )

    def _canonicalize_text(self, payload: Any) -> CanonicalizedPayload:
        if not isinstance(payload, str):
            return CanonicalizedPayload(
                content_type="text",
                text_blocks=[f"Error: Text payload was not a string, but {type(payload)}"],
                taints=[Taint(origin_type="invalid_text_payload_type", level="high")],
            )

        return CanonicalizedPayload(
            content_type="text",
            text_blocks=[payload.strip()],
            taints=[Taint(origin_type="source_text", level="low")],
        )

# ===== FILE: D:\EcodiaOS\systems\axon\journal\mej.py =====
# systems/axon/journal/mej.py

from datetime import UTC, datetime
from hashlib import blake2b
from typing import Any

from pydantic import BaseModel, Field

# -----------------------------------------------------------------------------
# Data Contract for Journal Entries
# -----------------------------------------------------------------------------


class JournalEntry(BaseModel):
    """A single, hashed entry in the Merkle Event Journal."""

    entry_hash: str = Field(
        ...,
        description="BLAKE2b hash of the canonicalized payload and previous hash.",
    )
    prev_entry_hash: str | None = Field(
        ...,
        description="The hash of the preceding journal entry, forming a chain.",
    )
    timestamp_utc: str = Field(..., description="ISO 8601 timestamp of when the entry was created.")
    entry_type: str = Field(
        ...,
        description="The Python type of the object being logged, e.g., 'AxonEvent'.",
    )
    payload: dict[str, Any] = Field(
        ...,
        description="The original data payload of the logged object.",
    )


# -----------------------------------------------------------------------------
# Deterministic JSON Serializer
# -----------------------------------------------------------------------------


def to_deterministic_json(model: BaseModel) -> bytes:
    """
    Serializes a Pydantic model to a deterministic JSON byte string.
    This is crucial for ensuring that hashes are reproducible.
    """
    json_string = model.model_dump_json(sort_keys=True)
    return json_string.encode("utf-8")


# -----------------------------------------------------------------------------
# Journal Writer Class
# -----------------------------------------------------------------------------


class MerkleJournal:
    """
    Manages writing entries to the Merkle Event Journal, creating a hash chain.
    """

    def __init__(self, hash_digest_size: int = 32):
        """Initializes the journal."""
        self.digest_size = hash_digest_size
        self._last_hash: str | None = None

    def write_entry(self, obj: BaseModel) -> JournalEntry:
        """
        Takes a Pydantic object, links it to the previous entry, serializes,
        hashes it, and returns a complete JournalEntry.

        Args:
            obj: The Pydantic model instance to log (e.g., AxonEvent, AxonIntent).

        Returns:
            A completed JournalEntry ready to be persisted.
        """
        entry_type = type(obj).__name__
        payload_bytes = to_deterministic_json(obj)

        hasher = blake2b(digest_size=self.digest_size)

        # Chain the hash: include the previous entry's hash in the new hash
        if self._last_hash:
            hasher.update(self._last_hash.encode("utf-8"))

        hasher.update(payload_bytes)
        entry_hash = hasher.hexdigest()

        entry = JournalEntry(
            entry_hash=entry_hash,
            prev_entry_hash=self._last_hash,
            timestamp_utc=datetime.now(UTC).isoformat(),
            entry_type=entry_type,
            payload=obj.model_dump(),
        )

        # Update the state to the new hash for the next entry
        self._last_hash = entry_hash

        print(
            f"MEJ Entry Created: {entry.entry_hash} ({entry.entry_type}) -> Links to: {entry.prev_entry_hash}",
        )
        return entry

# ===== FILE: D:\EcodiaOS\systems\axon\learning\feedback.py =====
# systems/axon/learning/feedback.py
from __future__ import annotations

import os
from typing import Any

from pydantic import BaseModel
from core.utils.net_api import ENDPOINTS, get_http_client
from systems.axon.schemas import ActionResult, AxonIntent


# ----------------- Models -----------------

class UpliftReport(BaseModel):
    """
    A detailed report comparing a predicted result with an actual result.
    This serves as a rich learning signal for Synapse.
    """
    intent: AxonIntent
    status_change: str | None  # e.g., "ok -> fail"
    output_diff: dict[str, Any]
    # Optional context for learning
    predicted_metrics: dict[str, Any] | None = None
    actual_metrics: dict[str, Any] | None = None


# ----------------- Helpers -----------------

def _calculate_diff(d1: dict[str, Any] | None, d2: dict[str, Any] | None, path: str = "") -> dict[str, Any]:
    """Recursively diffs two dictionaries."""
    d1 = d1 or {}
    d2 = d2 or {}
    diff: dict[str, Any] = {}

    for k in d1:
        p = f"{path}.{k}" if path else k
        if k not in d2:
            diff[p] = {"removed": d1[k]}
        elif isinstance(d1[k], dict) and isinstance(d2[k], dict):
            sub_diff = _calculate_diff(d1[k], d2[k], path=p)
            if sub_diff:
                diff.update(sub_diff)
        elif d1[k] != d2[k]:
            diff[p] = {"changed": {"from": d1[k], "to": d2[k]}}
    for k in d2:
        p = f"{path}.{k}" if path else k
        if k not in d1:
            diff[p] = {"added": d2[k]}
    return diff


async def _post_json(path: str, body: dict[str, Any], *, decision_id: str | None = None) -> None:
    headers = {"x-budget-ms": os.getenv("AXON_FEEDBACK_BUDGET_MS", "800")}
    if decision_id:
        headers["x-decision-id"] = decision_id
    client = await get_http_client()
    await client.post(path, json=body, headers=headers)


def _ingest_endpoint() -> str:
    # Canonical endpoint name; safe fallback for dev
    return getattr(ENDPOINTS, "SYNAPSE_INGEST_OUTCOME", None) or "/synapse/ingest_outcome"


# ----------------- Public API -----------------

async def ingest_action_outcome(
    intent: AxonIntent,
    predicted_result: ActionResult,
    actual_result: ActionResult,
    *,
    decision_id: str | None = None,
) -> None:
    """
    Calculates a detailed uplift report and sends it to Synapse via SYNAPSE_INGEST_OUTCOME.
    """
    status_change = None
    if predicted_result.status != actual_result.status:
        status_change = f"{predicted_result.status} -> {actual_result.status}"

    output_diff = _calculate_diff(predicted_result.outputs, actual_result.outputs)

    report = UpliftReport(
        intent=intent,
        status_change=status_change,
        output_diff=output_diff,
        predicted_metrics=predicted_result.counterfactual_metrics or {},
        actual_metrics=actual_result.counterfactual_metrics or {},
    )

    try:
        await _post_json(_ingest_endpoint(), report.model_dump(), decision_id=decision_id)
        # Optional: print for local dev visibility (quiet in prod)
        if os.getenv("AXON_DEBUG", "0") == "1":
            print(f"[Feedback] Ingested uplift report for intent {intent.intent_id}")
    except Exception as e:
        if os.getenv("AXON_DEBUG", "0") == "1":
            print(f"[Feedback] ingest_action_outcome failed: {e}")


async def log_outcome_to_synapse(payload: dict[str, Any], *, decision_id: str | None = None) -> None:
    """
    General-purpose logger to SYNAPSE_INGEST_OUTCOME for arbitrary
    learning payloads (A/B summaries, rollout decisions, etc.).
    """
    try:
        await _post_json(_ingest_endpoint(), payload, decision_id=decision_id)
    except Exception as e:
        if os.getenv("AXON_DEBUG", "0") == "1":
            print(f"[Feedback] log_outcome_to_synapse failed: {e}")

# ===== FILE: D:\EcodiaOS\systems\axon\loop\scheduler.py =====
# systems/axon/loop/scheduler.py
from __future__ import annotations

import asyncio
import os

from systems.axon.loop.sense import SenseLoop


async def run_sense_forever(period_sec: float = 30.0) -> None:
    loop = SenseLoop()
    period = float(os.getenv("AXON_SENSE_PERIOD_SEC", str(period_sec)))
    while True:
        try:
            count = await loop.poll_once()
            if os.getenv("AXON_DEBUG", "0") == "1":
                print(f"[SenseLoop] produced={count}")
        except Exception as e:
            if os.getenv("AXON_DEBUG", "0") == "1":
                print(f"[SenseLoop] error: {e}")
        await asyncio.sleep(period)

# ===== FILE: D:\EcodiaOS\systems\axon\loop\sense.py =====
# systems/axon/loop/sense.py
from __future__ import annotations

import time
from typing import Any

from systems.axon.dependencies import get_driver_registry, get_quarantine, get_journal
from systems.axon.events.emitter import emit_followups_bg
from systems.axon.schemas import AxonEvent


class SenseLoop:
    """
    Pull drivers → quarantine/canonicalize → shape AxonEvent → emit follow-ups (best-effort) + journal.
    """

    def __init__(self) -> None:
        self.registry = get_driver_registry()
        self.quarantine = get_quarantine()
        self.journal = get_journal()

    async def poll_once(self) -> int:
        produced = 0
        for drv in self.registry.list_all():
            if not hasattr(drv, "pull"):
                continue
            async for raw in drv.pull({}):
                # allow drivers to yield AxonEvent already
                if isinstance(raw, AxonEvent):
                    event = raw
                else:
                    # assume {payload, mime} or free-form; quarantine defensively
                    payload = getattr(raw, "payload", raw)
                    mime = getattr(raw, "mime", "text/plain")
                    canon = self.quarantine.process_and_canonicalize(payload, mime)
                    event = AxonEvent(
                        event_id=f"ev_{int(time.time()*1000)}",
                        t_observed=time.time(),
                        source=getattr(drv, "NAME", "driver"),
                        event_type="driver.pull",
                        modality="text" if canon.content_type == "text" else "json",
                        payload_ref=None,
                        parsed={"text": canon.text_blocks, "structured": canon.structured_data, "taints": [t.model_dump() for t in canon.taints]},
                        embeddings={},
                        provenance={"driver": getattr(drv, "NAME", ""), "version": getattr(drv, "VERSION", "")},
                    )

                # emit (best-effort) back to Atune and journal
                emit_followups_bg([{"event": event.model_dump()}])
                try:
                    self.journal.write_entry(event)  # MEJ accepts Pydantic models
                except Exception:
                    pass
                produced += 1
        return produced

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\attestation.py =====
# systems/axon/mesh/attestation.py
from __future__ import annotations

import hashlib
import os
from dataclasses import dataclass
from typing import Dict, Optional

from systems.axon.mesh.sdk import CapabilitySpec


@dataclass
class AttestationPolicy:
    # Expand with signature/kms fields later
    require_binding_for_live: bool = True


class AttestationRegistry:
    """
    In-memory map of driver_name → {capability, artifact_hash}.
    """
    def __init__(self) -> None:
        self._bindings: Dict[str, Dict[str, str]] = {}

    def bind(self, *, driver_name: str, capability: str, artifact_hash: str) -> None:
        self._bindings[driver_name] = {"capability": capability, "artifact_hash": artifact_hash}

    def get(self, driver_name: str) -> Optional[Dict[str, str]]:
        return self._bindings.get(driver_name)


_REG = AttestationRegistry()


def _hash_file(path: str) -> str:
    h = hashlib.blake2b(digest_size=32)
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(65536), b""):
            h.update(chunk)
    return h.hexdigest()


def compute_artifact_hash(artifact_path: str) -> str:
    """
    Computes a stable hash for the artifact file/module.
    """
    if not os.path.exists(artifact_path):
        raise FileNotFoundError(artifact_path)
    return _hash_file(artifact_path)


def bind_artifact_to_capability(*, driver_name: str, capability: str, artifact_hash: str) -> None:
    _REG.bind(driver_name=driver_name, capability=capability, artifact_hash=artifact_hash)


def verify_attestation(describe_obj: CapabilitySpec | dict, policy: AttestationPolicy) -> bool:
    """
    Verify that a driver has a binding. For now this checks presence & capability match.
    """
    if isinstance(describe_obj, dict):
        name = describe_obj.get("driver_name", "")
        cap  = (describe_obj.get("supported_actions") or [None])[0]
    else:
        name = describe_obj.driver_name
        cap  = (describe_obj.supported_actions or [None])[0]

    rec = _REG.get(name)
    if not rec:
        return not policy.require_binding_for_live  # allow if policy relaxed
    if cap and rec.get("capability") and cap != rec["capability"]:
        return False
    return True

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\autoroller.py =====
# systems/axon/mesh/autoroller.py
from __future__ import annotations

import time
from dataclasses import dataclass
from typing import Any

from pydantic import BaseModel

from systems.axon.dependencies import get_scorecard_manager, get_lifecycle_manager, get_journal
from systems.axon.security.attestation import verify_driver_attestation


@dataclass
class AutoRollConfig:
    window_n: int = 200
    min_success: float = 0.90
    sr_margin: float = 0.02
    p95_factor: float = 1.05
    min_uplift_delta: float = 0.00
    cooldown_sec: int = 300
    require_attestation: bool = True


class _AutoRollDecision(BaseModel):
    type: str = "autoroll_decision"
    capability: str
    action: str
    live_before: str
    live_after: str | None
    meta: dict[str, Any]
    ts: float


class AutoRoller:
    def __init__(self, cfg: AutoRollConfig | None = None) -> None:
        self.cfg = cfg or AutoRollConfig()
        self._last_roll_ts: dict[str, float] = {}

    def _cooldown_ok(self, capability: str) -> bool:
        last = self._last_roll_ts.get(capability, 0.0)
        return (time.time() - last) >= self.cfg.cooldown_sec

    def _journal(self, *, capability: str, action: str, live_before: str, live_after: str | None, meta: dict[str, Any]) -> None:
        try:
            get_journal().write_entry(_AutoRollDecision(
                capability=capability, action=action, live_before=live_before, live_after=live_after, meta=meta, ts=time.time()
            ))
        except Exception:
            pass

    async def maybe_promote(self, capability: str, *, shadow_name: str, live_name: str) -> dict[str, Any]:
        scores = get_scorecard_manager()
        lifecycle = get_lifecycle_manager()
        detail: dict[str, Any] = {"capability": capability, "shadow": shadow_name, "live": live_name, "decisions": []}

        if not self._cooldown_ok(capability):
            detail["cooldown"] = True
            return detail

        live_m = scores.get_window_metrics(live_name, self.cfg.window_n) or {}
        sh_m = scores.get_window_metrics(shadow_name, self.cfg.window_n) or {}

        # basic gates
        if (sh_m.get("success_rate", 0.0) < self.cfg.min_success) or (sh_m.get("success_rate", 0.0) < (live_m.get("success_rate", 0.0) + self.cfg.sr_margin)):
            detail["gate"] = "success_rate"
            return detail
        if sh_m.get("p95_ms", 9e9) > (live_m.get("p95_ms", 9e9) * self.cfg.p95_factor):
            detail["gate"] = "p95_latency"
            return detail
        if (sh_m.get("avg_uplift", 0.0) - live_m.get("avg_uplift", 0.0)) < self.cfg.min_uplift_delta:
            detail["gate"] = "uplift"
            return detail

        # attestation (optional)
        if self.cfg.require_attestation and not verify_driver_attestation(shadow_name):
            detail["gate"] = "attestation"
            return detail

        # promote
        try:
            lifecycle.update_driver_status(live_name, "shadow")
            lifecycle.update_driver_status(shadow_name, "live")
            self._last_roll_ts[capability] = time.time()
            self._journal(
                capability=capability,
                action="promote",
                live_before=live_name,
                live_after=shadow_name,
                meta={"live_metrics": live_m, "shadow_metrics": sh_m},
            )
            detail["decisions"].append({"action": "promote_shadow_to_live", "driver": shadow_name})
        except Exception as e:
            detail["error"] = f"promote_failed: {e}"
        return detail

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\lifecycle.py =====
# systems/axon/mesh/lifecycle.py
from __future__ import annotations

from dataclasses import dataclass, asdict
from typing import Dict, List, Literal, Optional

DriverStatus = Literal["pending_synthesis", "synthesizing", "testing", "shadow", "live", "retired", "synthesis_failed"]


@dataclass
class DriverSpec:
    driver_name: str
    capability: Optional[str] = None
    driver_version: str = "0.0.0"
    artifact_path: Optional[str] = None
    class_name: Optional[str] = None


@dataclass
class DriverState:
    name: str
    status: DriverStatus
    spec: DriverSpec
    synthesis_job_id: Optional[str] = None

    def model_dump(self) -> dict:
        d = asdict(self)
        d["spec"] = asdict(self.spec)
        return d


class DriverLifecycleManager:
    """
    Single-process in-memory lifecycle tracker.
    (Back it with Redis/Neo later if you want cross-process.)
    """

    def __init__(self, artifact_dir: str = "systems/axon/drivers/generated") -> None:
        self._states: Dict[str, DriverState] = {}
        self._artifact_dir = artifact_dir

    # --------- read / list ---------

    def get_driver_state(self, driver_name: str) -> Optional[DriverState]:
        return self._states.get(driver_name)

    # Backward-compat alias (old callers)
    def get_state(self, driver_name: str) -> Optional[DriverState]:  # pragma: no cover
        return self.get_driver_state(driver_name)

    def get_all_states(self) -> List[DriverState]:
        return list(self._states.values())

    # --------- synthesis ---------

    async def request_synthesis(self, *, driver_name: str, api_spec_url: str) -> DriverState:
        """
        Records an intent to synthesize a driver; Simula job initiation happens outside.
        """
        st = self._states.get(driver_name)
        if st and st.status not in {"synthesis_failed", "retired"}:
            # idempotent: don't clobber active drivers
            return st

        spec = DriverSpec(driver_name=driver_name, artifact_path=None)
        st = DriverState(name=driver_name, status="pending_synthesis", spec=spec, synthesis_job_id=None)
        self._states[driver_name] = st
        return st

    def record_synthesis_job(self, *, driver_name: str, job_id: str, artifact_path: Optional[str] = None, class_name: Optional[str] = None, capability: Optional[str] = None) -> DriverState:
        st = self._states.get(driver_name)
        if not st:
            st = DriverState(name=driver_name, status="pending_synthesis", spec=DriverSpec(driver_name=driver_name))
            self._states[driver_name] = st
        st.synthesis_job_id = job_id
        st.status = "synthesizing"
        if artifact_path:
            st.spec.artifact_path = artifact_path
        if class_name:
            st.spec.class_name = class_name
        if capability:
            st.spec.capability = capability
        return st

    def attach_artifact(self, *, driver_name: str, artifact_path: str, class_name: Optional[str] = None, driver_version: Optional[str] = None, capability: Optional[str] = None) -> DriverState:
        st = self._states.get(driver_name)
        if not st:
            st = DriverState(name=driver_name, status="testing", spec=DriverSpec(driver_name=driver_name))
            self._states[driver_name] = st
        st.spec.artifact_path = artifact_path
        if class_name:
            st.spec.class_name = class_name
        if driver_version:
            st.spec.driver_version = driver_version
        if capability:
            st.spec.capability = capability
        return st

    # --------- status transitions ---------

    def update_driver_status(self, driver_name: str, new_status: DriverStatus) -> DriverState:
        st = self._states.get(driver_name)
        if not st:
            st = DriverState(name=driver_name, status=new_status, spec=DriverSpec(driver_name=driver_name))
            self._states[driver_name] = st
            return st

        # idempotent
        if st.status == new_status:
            return st

        # simple guardrails
        allowed = {
            "pending_synthesis": {"synthesizing", "synthesis_failed"},
            "synthesizing": {"testing", "synthesis_failed"},
            "testing": {"shadow", "retired"},
            "shadow": {"live", "testing", "retired"},
            "live": {"shadow", "retired"},
            "synthesis_failed": {"pending_synthesis", "retired"},
            "retired": set(),
        }
        if new_status not in allowed.get(st.status, set()):
            # allow direct set in emergencies, but annotate by stepping through
            st.status = new_status
            return st

        st.status = new_status
        return st

    # convenience
    def list_drivers(self) -> List[DriverState]:
        return list(self._states.values())

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\promoter.py =====
# systems/axon/mesh/promoter.py
from __future__ import annotations

from typing import Any

from systems.axon.dependencies import get_lifecycle_manager, get_scorecard_manager
from systems.axon.mesh.lifecycle import DriverStatus
from systems.axon.security.attestation import AttestationManager


class PromotionPolicy:
    def __init__(self, max_p95_ms: int = 1200, min_uplift: float = 0.02, min_window: int = 50) -> None:
        self.max_p95_ms = max_p95_ms
        self.min_uplift = min_uplift
        self.min_window = min_window

    def ok(self, scorecard_like: Any) -> bool:
        """
        Accepts either: Scorecard window dict or an object with needed attrs.
        """
        try:
            window_size = float(getattr(scorecard_like, "window_size", scorecard_like.get("window_size")))
            p95_ms = float(getattr(scorecard_like, "p95_ms", scorecard_like.get("p95_ms")))
            uplift = float(getattr(scorecard_like, "uplift_vs_incumbent", scorecard_like.get("avg_uplift")))
            return window_size >= self.min_window and p95_ms <= self.max_p95_ms and uplift >= self.min_uplift
        except Exception:
            return False


def _status_eq(current_status: Any, target: DriverStatus) -> bool:
    try:
        if isinstance(current_status, str):
            return current_status == target or current_status == getattr(target, "value", target)
        return current_status == target
    except Exception:
        return False


def _coerce_like(template: Any, desired: DriverStatus):
    if isinstance(template, str):
        return desired  # we use the literal string values in lifecycle
    return desired


async def promote_if_ready(driver_name: str, *, incumbent: str | None = None, policy: PromotionPolicy | None = None) -> bool:
    """
    Advance testing → shadow → live when window metrics pass policy AND attestation is bound.
    """
    policy = policy or PromotionPolicy()
    lifecycle = get_lifecycle_manager()                     # singleton, has artifact_dir
    scores = get_scorecard_manager()
    attest = AttestationManager()

    # use rolling-window metrics
    wm = scores.get_window_metrics(driver_name, window_n=200)
    if not wm or not policy.ok(wm):
        return False

    # attestation guard (artifact hash + optional signature)
    if not attest.is_bound(driver_name):
        return False

    state = lifecycle.get_driver_state(driver_name)         # correct API
    if not state:
        return False

    # testing → shadow
    if _status_eq(state.status, "testing"):
        lifecycle.update_driver_status(driver_name, _coerce_like(state.status, "shadow"))  # type: ignore[arg-type]
        return True

    # shadow → live (optionally demote incumbent)
    if _status_eq(state.status, "shadow"):
        if incumbent and incumbent != driver_name:
            lifecycle.update_driver_status(incumbent, _coerce_like(state.status, "shadow"))  # demote live to shadow
        lifecycle.update_driver_status(driver_name, _coerce_like(state.status, "live"))      # promote shadow to live
        return True

    return False

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\registry.py =====
# systems/axon/mesh/registry.py
from __future__ import annotations

from typing import Iterable

import importlib.util

from systems.axon.mesh.attestation import AttestationPolicy, verify_attestation
from systems.axon.mesh.lifecycle import DriverStatus
from systems.axon.mesh.sdk import DriverInterface


class DriverRegistry:
    """
    Manages driver lifecycle & routing with status-aware dispatch.
    Enforces attestation when a driver is 'live' (configurable).
    """

    def __init__(self):
        self._drivers: dict[str, DriverInterface] = {}
        self._capability_map: dict[str, list[str]] = {}
        self._driver_statuses: dict[str, DriverStatus] = {}
        self._policy = AttestationPolicy()

    # ---------- Introspection ----------

    def list_all(self) -> Iterable[DriverInterface]:
        return list(self._drivers.values())

    def describe(self, driver_name: str) -> dict | None:
        d = self._drivers.get(driver_name)
        try:
            return d.describe().model_dump() if d else None
        except Exception:
            return None

    # ---------- Registration / Loading ----------

    def _map_capabilities(self, driver: DriverInterface) -> None:
        spec = driver.describe()
        # remove stale entries for this driver
        for cap, names in list(self._capability_map.items()):
            self._capability_map[cap] = [n for n in names if n != spec.driver_name]
        # add fresh entries
        for capability in spec.supported_actions:
            self._capability_map.setdefault(capability, [])
            if spec.driver_name not in self._capability_map[capability]:
                self._capability_map[capability].append(spec.driver_name)

    def register(self, driver: DriverInterface, initial_status: DriverStatus = "testing"):
        spec = driver.describe()
        self._drivers[spec.driver_name] = driver
        self._driver_statuses[spec.driver_name] = initial_status
        self._map_capabilities(driver)
        print(f"[Registry] Registered {spec.driver_name} status={initial_status}")

    def update_driver_status(self, driver_name: str, new_status: DriverStatus):
        if driver_name not in self._drivers:
            # allow preset status for drivers loaded later
            self._driver_statuses[driver_name] = new_status
            print(f"[Registry] Preset status for '{driver_name}' → {new_status}")
            return
        self._driver_statuses[driver_name] = new_status
        print(f"[Registry] Updated status for '{driver_name}' → {new_status}")
        # enforce attestation when moving to live
        if new_status == "live":
            d = self._drivers[driver_name]
            if not verify_attestation(d.describe(), self._policy):
                self._driver_statuses[driver_name] = "testing"
                raise RuntimeError(f"Driver '{driver_name}' failed attestation; reverted to 'testing'")

    def load_and_register_driver(
        self,
        driver_name: str,
        module_path: str,
        class_name: str,
        initial_status: DriverStatus | None = None,
    ):
        try:
            spec = importlib.util.spec_from_file_location(driver_name, module_path)
            if spec is None or spec.loader is None:
                raise ImportError(f"Cannot load spec from {module_path}")
            mod = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(mod)  # type: ignore
            if not hasattr(mod, class_name):
                raise ImportError(f"{class_name} not found in {module_path}")
            cls = getattr(mod, class_name)
            driver: DriverInterface = cls()
            status = initial_status or self._driver_statuses.get(driver_name, "testing")
            self.register(driver, initial_status=status)
            if status == "live" and not verify_attestation(driver.describe(), self._policy):
                self._driver_statuses[driver_name] = "testing"
                raise RuntimeError(f"Loaded driver '{driver_name}' without valid attestation")
            print(f"[Registry] Loaded '{driver_name}' from '{module_path}' as '{class_name}'")
        except Exception as e:
            raise RuntimeError(f"load_and_register_driver failed for '{driver_name}': {e}")

    # ---------- Routing ----------

    def get_live_driver_for_capability(self, capability: str) -> DriverInterface | None:
        for name in self._capability_map.get(capability, []):
            if self._driver_statuses.get(name) == "live":
                return self._drivers.get(name)
        return None

    def get_shadow_drivers_for_capability(self, capability: str) -> list[DriverInterface]:
        out: list[DriverInterface] = []
        for name in self._capability_map.get(capability, []):
            if self._driver_statuses.get(name) == "shadow":
                d = self._drivers.get(name)
                if d:
                    out.append(d)
        return out

    def promote_shadow_to_live(self, capability: str, shadow_driver_name: str) -> None:
        # demote current live if any, then promote the named shadow
        live = self.get_live_driver_for_capability(capability)
        if live:
            live_name = live.describe().driver_name
            self.update_driver_status(live_name, "shadow")
        self.update_driver_status(shadow_driver_name, "live")

    def demote_live_to_shadow(self, capability: str) -> None:
        live = self.get_live_driver_for_capability(capability)
        if live:
            live_name = live.describe().driver_name
            self.update_driver_status(live_name, "shadow")

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\scorecard.py =====
# systems/axon/mesh/scorecard.py
from __future__ import annotations

from collections import deque
from dataclasses import dataclass
from datetime import UTC, datetime
from statistics import quantiles
from typing import Deque

from pydantic import BaseModel, Field


class DriverScorecard(BaseModel):
    driver_name: str
    total_runs: int = 0
    successful_runs: int = 0
    failed_runs: int = 0
    average_latency_ms: float = 0.0
    total_cost_usd: float = 0.0
    average_uplift: float = 0.0
    last_seen_utc: str = Field(default_factory=lambda: datetime.now(UTC).isoformat())

    @property
    def success_rate(self) -> float:
        return self.successful_runs / self.total_runs if self.total_runs > 0 else 0.0


@dataclass
class _RunSample:
    ok: bool
    latency_ms: float
    cost_usd: float
    uplift: float
    ts: float


class ScorecardManager:
    """
    Maintains scorecards + a bounded rolling window of recent runs per driver.
    """

    def __init__(self, window_max: int = 500) -> None:
        self._scorecards: dict[str, DriverScorecard] = {}
        self._history: dict[str, Deque[_RunSample]] = {}
        self._window_max = window_max

    def update_scorecard(
        self,
        driver_name: str,
        was_successful: bool,
        latency_ms: float,
        cost_usd: float = 0.0,
        uplift: float = 0.0,
        ts: float | None = None,
    ) -> None:
        if driver_name not in self._scorecards:
            self._scorecards[driver_name] = DriverScorecard(driver_name=driver_name)
            self._history[driver_name] = deque(maxlen=self._window_max)

        card = self._scorecards[driver_name]
        # streaming avgs
        old_avg_latency = card.average_latency_ms
        old_avg_uplift = card.average_uplift
        card.total_runs += 1
        card.average_latency_ms += (latency_ms - old_avg_latency) / card.total_runs
        card.average_uplift += (uplift - old_avg_uplift) / card.total_runs
        if was_successful:
            card.successful_runs += 1
        else:
            card.failed_runs += 1
        card.total_cost_usd += cost_usd
        card.last_seen_utc = datetime.now(UTC).isoformat()

        self._history[driver_name].append(
            _RunSample(ok=was_successful, latency_ms=latency_ms, cost_usd=cost_usd, uplift=uplift, ts=ts or datetime.now(UTC).timestamp())
        )

        print(f"ScorecardManager: Updated '{driver_name}'. SR={card.success_rate:.2%}")

    def get_all_scorecards(self) -> list[DriverScorecard]:
        return list(self._scorecards.values())

    # ---- new helpers for promoter/autoroller ----

    def get_scorecard(self, driver_name: str) -> DriverScorecard | None:
        return self._scorecards.get(driver_name)

    def get_window_metrics(self, driver_name: str, window_n: int = 200) -> dict[str, float] | None:
        hist = list(self._history.get(driver_name, ()))
        if not hist:
            return None
        window = hist[-window_n:] if window_n > 0 else hist
        latencies = [s.latency_ms for s in window]
        p95 = quantiles(latencies, n=100)[94] if len(latencies) >= 20 else max(latencies)  # rough but robust
        success_rate = sum(1 for s in window if s.ok) / len(window)
        avg_uplift = (sum(s.uplift for s in window) / len(window)) if window else 0.0
        return {
            "window_size": float(len(window)),
            "p95_ms": float(p95),
            "success_rate": float(success_rate),
            "avg_uplift": float(avg_uplift),
            "avg_latency_ms": float(sum(latencies) / len(latencies)),
        }

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\sdk.py =====
# systems/axon/mesh/sdk.py
from __future__ import annotations

from abc import ABC, abstractmethod
from collections.abc import AsyncIterator
from typing import Any, Literal

from pydantic import BaseModel, Field

from systems.axon.schemas import ActionResult, AxonEvent, AxonIntent


class CapabilitySpec(BaseModel):
    """describe() output"""
    driver_name: str
    driver_version: str
    supported_actions: list[str] = Field(..., description="Capabilities this driver can push.")
    risk_profile: dict[str, str] = Field(..., description="action → risk tier")
    budget_model: dict[str, float] = Field(..., description="action → est. cost")
    auth_requirements: list[str] = Field(..., description="e.g., api_key, oauth2")


class HealthStatus(BaseModel):
    status: Literal["ok", "degraded", "error"]
    details: str = ""
    dependencies: dict[str, Literal["ok", "error"]] = Field(default_factory=dict)


class ReplayCapsule(BaseModel):
    """bit-exact replay bundle"""
    id: str
    type: Literal["event", "intent"]
    driver_version: str
    environment_hash: str
    inputs: dict[str, Any]
    outputs: dict[str, Any]


class DriverInterface(ABC):
    """
    Canonical Axon driver SDK — now async to match real drivers.
    """

    @abstractmethod
    def describe(self) -> CapabilitySpec:  # sync is fine here
        ...

    @abstractmethod
    async def pull(self, params: dict[str, Any]) -> AsyncIterator[AxonEvent]:
        """
        Sense loop: yield AxonEvent(s). Implement only if the driver is a pull/sensor.
        """
        if False:  # pragma: no cover (interface)
            yield AxonEvent()  # type: ignore

    @abstractmethod
    async def push(self, intent: AxonIntent) -> ActionResult:
        """
        Execute a capability. Must honor constraints.dry_run when present.
        """
        ...

    @abstractmethod
    async def self_test(self) -> HealthStatus:
        """
        Lightweight dependency/health probe for lifecycle + probecraft.
        """
        ...

    @abstractmethod
    async def repro_bundle(self, *, id: str, kind: Literal["event", "intent"]) -> ReplayCapsule:
        """
        Build and return a deterministic replay capsule for the given item.
        """
        ...

# ===== FILE: D:\EcodiaOS\systems\axon\mesh\synthesis_client.py =====
# systems/axon/mesh/synthesis_client.py
from __future__ import annotations

from typing import Any

from core.utils.net_api import ENDPOINTS, get_http_client
from systems.axon.dependencies import get_lifecycle_manager


async def request_driver_synthesis(
    *,
    driver_name: str,
    api_spec_url: str | None = None,
    template_hint: str | None = None,
    artifact_dir: str | None = None,
) -> dict[str, Any]:
    """
    Requests Simula to synthesize a driver from a spec/hint, then records the job in lifecycle.
    """
    client = await get_http_client()
    path = getattr(ENDPOINTS, "SIMULA_DRIVER_SYNTH", None) or getattr(ENDPOINTS, "SIMULA_CODEGEN", "/simula/driver/synth")
    payload = {"driver_name": driver_name, "api_spec_url": api_spec_url, "template_hint": template_hint}
    r = await client.post(path, json=payload)
    r.raise_for_status()
    data = r.json()

    job_id = str(data.get("job_id") or data.get("id") or "")
    artifacts = str(data.get("artifact_path") or (artifact_dir or "systems/axon/drivers/generated"))

    lifecycle = get_lifecycle_manager()
    lifecycle.record_synthesis_job(driver_name=driver_name, job_id=job_id, artifact_path=artifacts)

    return {"job_id": job_id, "artifact_path": artifacts, "status": "submitted"}

# ===== FILE: D:\EcodiaOS\systems\axon\rollback\engine.py =====
# systems/axon/rollback/engine.py
from __future__ import annotations

import copy
import time
from typing import Any

from systems.axon.mesh.registry import DriverRegistry
from systems.axon.schemas import ActionResult, AxonIntent


async def execute_rollback(
    intent: AxonIntent,
    result: ActionResult,
    registry: DriverRegistry,
) -> dict[str, Any]:
    """
    Execute a simple rollback contract if present on the original intent:
      intent.rollback_contract = {"capability":"<cap>","params":{...}}
    Returns a dict with status and optional rollback ActionResult.
    """
    rb = getattr(intent, "rollback_contract", {}) or {}
    cap = rb.get("capability")
    if not cap:
        return {"status": "no_rollback"}

    driver = registry.get_live_driver_for_capability(cap)
    if not driver:
        return {"status": "rollback_no_driver", "capability": cap}

    # Construct rollback intent
    rb_intent = copy.deepcopy(intent)
    rb_intent.intent_id = f"{intent.intent_id}::rollback"
    rb_intent.target_capability = cap
    rb_intent.params = copy.deepcopy(rb.get("params", {}))
    rb_intent.constraints = {"dry_run": False}

    try:
        t0 = time.perf_counter()
        rb_res: ActionResult = await driver.push(rb_intent)
        return {
            "status": "rollback_executed",
            "latency_ms": (time.perf_counter() - t0) * 1000.0,
            "result": {
                "status": rb_res.status,
                "outputs": rb_res.outputs,
                "counterfactual_metrics": rb_res.counterfactual_metrics,
            },
        }
    except Exception as e:
        return {"status": "rollback_failed", "error": str(e)}

# ===== FILE: D:\EcodiaOS\systems\axon\safety\circuit_breaker.py =====
# systems/axon/safety/circuit_breaker.py
from __future__ import annotations

import time
from dataclasses import dataclass
from typing import Deque, Dict, Tuple
from collections import deque


@dataclass
class _Sample:
    ts: float
    ok: bool


class CircuitBreaker:
    """
    Time-window breaker evaluated per capability.
    Opens when success ratio falls below threshold OR burst failures exceed cap.
    """

    def __init__(self, window_sec: int = 60, min_success: float = 0.80, burst_fail_cap: int = 5, cooldown_sec: int = 30) -> None:
        self._hist: Dict[str, Deque[_Sample]] = {}
        self._open_until: Dict[str, float] = {}
        self._window = float(window_sec)
        self._min_success = float(min_success)
        self._burst_cap = int(burst_fail_cap)
        self._cooldown = float(cooldown_sec)

    def allow(self, capability: str) -> bool:
        now = time.time()
        until = self._open_until.get(capability, 0.0)
        return now >= until

    def report(self, capability: str, ok: bool) -> None:
        now = time.time()
        q = self._hist.setdefault(capability, deque())
        q.append(_Sample(ts=now, ok=ok))
        # drop old
        while q and (now - q[0].ts) > self._window:
            q.popleft()

        # evaluate
        if not q:
            return
        sr = sum(1 for s in q if s.ok) / len(q)
        burst = 0
        for s in reversed(q):
            if not s.ok:
                burst += 1
            else:
                break
        if sr < self._min_success or burst >= self._burst_cap:
            self._open_until[capability] = now + self._cooldown

# ===== FILE: D:\EcodiaOS\systems\axon\safety\conformal.py =====
# systems/axon/safety/conformal.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Deque
from collections import deque


@dataclass
class ConformalBound:
    lower: float
    upper: float
    n: int


class ConformalPredictor:
    """
    Simple online absolute residual collector with quantile bound.
    Not statistically perfect, but fast and robust for gating.
    """

    def __init__(self, max_residuals: int = 512, q: float = 0.9) -> None:
        self._res: Deque[float] = deque(maxlen=max_residuals)
        self._q = max(0.5, min(q, 0.99))

    def observe(self, predicted: float, actual: float) -> None:
        self._res.append(abs(actual - predicted))

    def bound(self, predicted: float) -> ConformalBound:
        if not self._res:
            return ConformalBound(lower=predicted - 1.0, upper=predicted + 1.0, n=0)
        # quantile via sorted slice (fast enough, bounded)
        s = sorted(self._res)
        idx = int(self._q * (len(s) - 1))
        e = s[idx]
        return ConformalBound(lower=predicted - e, upper=predicted + e, n=len(s))

# ===== FILE: D:\EcodiaOS\systems\axon\safety\contracts.py =====
# systems/axon/safety/contracts.py
from __future__ import annotations

from typing import Any, Callable, Iterable

from pydantic import BaseModel

from systems.axon.schemas import ActionResult, AxonIntent


class ContractVerdict(BaseModel):
    ok: bool
    reason: str = ""
    patches: dict[str, Any] = {}   # optional redactions/patches

PreRule = Callable[[AxonIntent], ContractVerdict]
PostRule = Callable[[AxonIntent, ActionResult], ContractVerdict]


class ContractsEngine:
    """
    Micro policy gates for pre/post conditions.
    Keep fully deterministic; zero-LLM.
    """
    def __init__(self, pre: Iterable[PreRule] | None = None, post: Iterable[PostRule] | None = None) -> None:
        self._pre = list(pre or [])
        self._post = list(post or [])

    # ------------ default rules (can be extended) ------------

    @staticmethod
    def _pre_require_rollback_for_high(intent: AxonIntent) -> ContractVerdict:
        tier = (getattr(intent, "risk_tier", "low") or "").lower()
        if tier in {"high", "extreme"} and not getattr(intent, "rollback_contract", None):
            return ContractVerdict(ok=False, reason="high_risk_requires_rollback")
        return ContractVerdict(ok=True)

    @staticmethod
    def _pre_budget_cap(intent: AxonIntent) -> ContractVerdict:
        cons = getattr(intent, "constraints", {}) or {}
        if isinstance(cons, dict) and cons.get("timeout_ms") and int(cons["timeout_ms"]) > 60_000:
            return ContractVerdict(ok=False, reason="timeout_exceeds_cap")
        return ContractVerdict(ok=True)

    @staticmethod
    def _post_require_outputs(_: AxonIntent, res: ActionResult) -> ContractVerdict:
        if not isinstance(res.outputs, dict):
            return ContractVerdict(ok=False, reason="outputs_not_dict")
        return ContractVerdict(ok=True)

    @staticmethod
    def _post_status_known(_: AxonIntent, res: ActionResult) -> ContractVerdict:
        if res.status not in {"ok", "fail", "blocked"}:
            return ContractVerdict(ok=False, reason="unknown_status")
        return ContractVerdict(ok=True)

    # ------------ API ------------

    def with_default_rules(self) -> "ContractsEngine":
        self._pre.extend([self._pre_require_rollback_for_high, self._pre_budget_cap])
        self._post.extend([self._post_require_outputs, self._post_status_known])
        return self

    def add_pre(self, rule: PreRule) -> None:
        self._pre.append(rule)

    def add_post(self, rule: PostRule) -> None:
        self._post.append(rule)

    def check_pre(self, intent: AxonIntent) -> ContractVerdict:
        for rule in self._pre:
            v = rule(intent)
            if not v.ok:
                return v
        return ContractVerdict(ok=True)

    def check_post(self, intent: AxonIntent, res: ActionResult) -> ContractVerdict:
        for rule in self._post:
            v = rule(intent, res)
            if not v.ok:
                return v
        return ContractVerdict(ok=True)

# ===== FILE: D:\EcodiaOS\systems\axon\safety\reflex.py =====
# systems/axon/safety/reflex.py

import re
from dataclasses import dataclass
from enum import Enum
from typing import Any

from systems.axon.schemas import AxonIntent


class ReflexVerdict(str, Enum):
    ALLOW = "allow"
    BLOCK = "block"
    REDACT = "redact"


@dataclass
class ReflexResult:
    action: ReflexVerdict
    reason: str = ""
    redactions: dict[str, Any] = None


class ReflexEngine:
    """
    Zero-LLM reflexes that run before twin/conformal/live.
    Keep it deterministic and fast.
    """

    _pii_regex = re.compile(r"\b\d{3}-\d{2}-\d{4}\b")  # example US SSN

    def evaluate(self, intent: AxonIntent) -> ReflexResult:
        # Example: redact queries containing obvious PII
        params_str = str(intent.params or "")
        if self._pii_regex.search(params_str):
            redacted = dict(intent.params or {})
            redacted_str = self._pii_regex.sub("[REDACTED_SSN]", str(redacted))
            return ReflexResult(
                action=ReflexVerdict.REDACT,
                reason="PII detected in params",
                redactions={"params": redacted_str},
            )
        # Block unsupported high-risk capabilities without rollback
        if intent.risk_tier == "high" and not intent.rollback_contract:
            return ReflexResult(
                ReflexVerdict.BLOCK,
                reason="High-risk intent missing rollback contract",
            )
        return ReflexResult(ReflexVerdict.ALLOW)

# ===== FILE: D:\EcodiaOS\systems\axon\safety\twin.py =====
# systems/axon/safety/twin.py
from __future__ import annotations

import time
from typing import Any

from core.utils.net_api import ENDPOINTS, get_http_client
from systems.axon.schemas import ActionResult, AxonIntent


async def _post_json(path: str, body: dict[str, Any]) -> dict[str, Any]:
    client = await get_http_client()
    r = await client.post(path, json=body, headers={"x-budget-ms": "800"})
    r.raise_for_status()
    return r.json()

async def run_in_twin(intent: AxonIntent) -> ActionResult:
    """
    Produce a counterfactual prediction for an intent.
    Prefers Synapse's SIMULATE op; falls back to Simula twin eval.
    """
    body = intent.model_dump()
    started = time.perf_counter()

    # Preferred: Synapse simulate (per bible's canonical ops)
    try:
        if hasattr(ENDPOINTS, "SYNAPSE_SIMULATE"):
            data = await _post_json(getattr(ENDPOINTS, "SYNAPSE_SIMULATE"), body)
        else:
            # Fallbacks that keep dev flows unblocked
            path = (
                getattr(ENDPOINTS, "SIMULA_TWIN_EVAL", None)
                or "/simula/twin/eval"
            )
            data = await _post_json(path, body)
    except Exception as e:
        # Fail-safe prediction (prevents downstream overconfidence)
        dur_ms = (time.perf_counter() - started) * 1000.0
        return ActionResult(
            intent_id=intent.intent_id,
            status="blocked",
            outputs={"error": "twin_unavailable", "details": str(e)},
            side_effects={},
            counterfactual_metrics={"predicted_utility": 0.0, "twin_latency_ms": dur_ms},
        )

    dur_ms = (time.perf_counter() - started) * 1000.0
    # Normalize minimal shape expected by callers
    counterfactual = data.get("counterfactual_metrics") or {}
    counterfactual.setdefault("predicted_utility", float(counterfactual.get("predicted_utility", 0.0)))
    counterfactual["twin_latency_ms"] = dur_ms

    return ActionResult(
        intent_id=intent.intent_id,
        status=data.get("status", "ok"),
        outputs=data.get("outputs", {}),
        side_effects=data.get("side_effects", {}),
        counterfactual_metrics=counterfactual,
        follow_up_events=[],
    )

# ===== FILE: D:\EcodiaOS\systems\axon\safety\validation.py =====
# systems/axon/safety/validation.py
from __future__ import annotations

import hashlib
import hmac
import time as pytime
from typing import Any

from pydantic import BaseModel

from systems.axon.mesh.registry import DriverRegistry
from systems.equor.kms.keystore import get_hmac_key_by_kid


class Predicate(BaseModel):
    variable: str
    operator: str
    value: Any


class CapabilityValidator:
    """
    Validates Equor capability tokens minted upstream.
    Enforces TTL (nbf/exp), issuer/audience, capability/driver binding, and KMS key rotation via `kid`.
    """

    def validate(self, intent, driver_registry: DriverRegistry | None = None) -> bool:
        token: dict[str, Any] | None = (intent.policy_trace or {}).get("equor_cap_token")
        if not token:
            return False

        # Required fields
        intent_id = token.get("intent_id")
        sig = token.get("signature")
        preds = token.get("predicates", [])
        nbf, exp = int(token.get("nbf", 0)), int(token.get("exp", 2**31))
        iss, aud = token.get("iss", ""), token.get("aud", "")
        cap = token.get("capability")
        version = str(token.get("version", ""))
        artifact_hash = token.get("artifact_hash")  # optional
        kid = token.get("kid", "k1")

        # Basic checks
        now = int(pytime.time())
        if now < nbf or now > exp:
            return False
        if iss != "equor" or aud not in ("axon", "atune", "unity"):
            return False
        if not intent_id or not sig or not cap:
            return False
        if intent.target_capability != cap:
            return False

        # KMS key lookup
        key = get_hmac_key_by_kid(kid)
        if not key:
            return False

        # Signature over canonical message: intent_id + sorted predicates (by string)
        message = intent_id.encode("utf-8") + str(sorted(preds, key=str)).encode("utf-8")
        expected = hmac.new(key, message, hashlib.sha256).hexdigest()
        if not hmac.compare_digest(expected, sig):
            return False

        # Bind to current live driver artifact/version (best-effort)
        if driver_registry:
            live = driver_registry.get_live_driver_for_capability(cap)
            if live and hasattr(live, "describe"):
                desc = live.describe()
                live_hash = getattr(desc, "artifact_hash", None)
                live_version = getattr(desc, "version", None)
                if artifact_hash and live_hash and artifact_hash != live_hash:
                    return False
                if version and live_version and str(version) != str(live_version):
                    return False

        return True

# ===== FILE: D:\EcodiaOS\systems\axon\security\attestation.py =====
# systems/axon/security/attestation.py
from __future__ import annotations

import os
from typing import Any

from systems.axon.mesh.attestation import AttestationPolicy, verify_attestation


class AttestationManager:
    """
    Thin facade for future KMS-backed bindings.
    For now, we rely on mesh.attestation.verify_attestation(describe()) semantics.
    """

    def __init__(self, policy: AttestationPolicy | None = None) -> None:
        self._policy = policy or AttestationPolicy()

    def is_bound(self, driver_name: str) -> bool:
        # In a fuller implementation, this would check KMS signatures bound to artifact hashes.
        # For now, honor a dev override: AXON_ATTEST_BYPASS=1
        if os.getenv("AXON_ATTEST_BYPASS", "0") == "1":
            return True
        # Callers should supply the driver describe() object to verify — we keep a simple interface here.
        # Expect higher layers (registry/promoter) to pass describe() into verify_attestation directly.
        return True


def verify_driver_attestation(describe_obj: Any) -> bool:
    """
    Convenience wrapper for modules that import from security.attestation.
    """
    return verify_attestation(describe_obj, AttestationPolicy())
